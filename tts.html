<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Train Your Voice → Letters & Numbers</title>
<meta name="viewport" content="width=device-width, initial-scale=1">

<style>
  body { font-family: Arial; padding: 20px; background: #111; color: #eee; }
  button { padding: 10px 14px; margin: 5px; border-radius: 6px; border: none; }
  .primary { background: #29f; color: #fff; }
  .danger { background: #d33; color: #fff; }
  .card { background: #222; padding: 15px; border-radius: 10px; margin-bottom: 20px; }
  .log { background: #000; padding: 10px; height: 140px; overflow-y: auto; white-space: pre; }
  .big { font-size: 20px; margin: 10px 0; }
</style>
</head>
<body>

<h2>Train Your Voice (Letters + Numbers)</h2>

<div class="card">
  <p>Click a character below and speak it the way YOU pronounce it.</p>
  <div id="buttons"></div>
  <p><button class="danger" onclick="clearTraining()">Clear All Training</button></p>
</div>

<div class="card">
  <h3>Recognition</h3>
  <button class="primary" onclick="startRecognition()">Start Recognizing</button>
  <button onclick="stopRecognition()">Stop</button>

  <div class="big">Output: <span id="out"></span></div>
</div>

<div class="card">
  <h3>Log</h3>
  <div id="log" class="log"></div>
</div>

<script>
// ===== GLOBAL =====
let audioCtx;
let stream;
let processor;
let training = {};  // letter → array of feature vectors
let running = false;

// Load saved training
if (localStorage.voiceTraining) {
  training = JSON.parse(localStorage.voiceTraining);
}

// ===== UI buttons for A–Z and 0–9 =====
const chars = [];
for (let i=0;i<26;i++) chars.push(String.fromCharCode(97+i)); // a-z
for (let i=0;i<=9;i++) chars.push(String(i)); // numbers

const btnArea = document.getElementById("buttons");
chars.forEach(c=>{
  const b = document.createElement("button");
  b.textContent = c.toUpperCase();
  b.onclick = ()=>trainChar(c);
  btnArea.appendChild(b);
});

// Logging helper
function log(msg){
  let box = document.getElementById("log");
  box.textContent += msg+"\n";
  box.scrollTop = box.scrollHeight;
}

// ===== AUDIO SETUP =====
async function initAudio() {
  if(!audioCtx) audioCtx = new AudioContext();
  stream = await navigator.mediaDevices.getUserMedia({audio:true});
  const src = audioCtx.createMediaStreamSource(stream);
  processor = audioCtx.createScriptProcessor(2048, 1, 1);
  src.connect(processor);
  processor.connect(audioCtx.destination);
}

// Extract simple FFT + energy features
function extractFeatures(inputBuffer) {
  const raw = inputBuffer.getChannelData(0);
  const size = 1024;
  const segment = raw.slice(0, size);

  // Basic energy
  let energy = 0;
  for (let i=0;i<segment.length;i++) energy += segment[i]*segment[i];
  energy /= segment.length;

  // Basic FFT
  const fft = new Float32Array(size);
  const re = new Float32Array(size);
  const im = new Float32Array(size);
  for (let i=0;i<size;i++) re[i] = segment[i];
  // naive FFT
  for (let k=0;k<size;k++){
    let sumRe = 0, sumIm = 0;
    for(let n=0;n<size;n++){
      const ang = (2*Math.PI*k*n)/size;
      sumRe += re[n]*Math.cos(ang) + im[n]*Math.sin(ang);
      sumIm += -re[n]*Math.sin(ang) + im[n]*Math.cos(ang);
    }
    fft[k] = Math.sqrt(sumRe*sumRe + sumIm*sumIm);
  }

  // Downsample FFT into 16 bins
  const bins = 16;
  const f = [];
  const step = Math.floor(size/bins);
  for(let b=0;b<bins;b++){
    let sum = 0;
    for(let i=b*step;i<(b+1)*step;i++){
      sum += fft[i];
    }
    f.push(sum);
  }

  f.push(energy);
  return f;
}

// Euclidean distance
function dist(a,b){
  let s=0;
  for(let i=0;i<a.length;i++){
    let d=a[i]-b[i];
    s+=d*d;
  }
  return Math.sqrt(s);
}

// Train a single letter/number
async function trainChar(ch){
  log("Training for: "+ch);

  await initAudio();

  return new Promise(resolve=>{
    let collected = [];

    processor.onaudioprocess = (e)=>{
      const input = e.inputBuffer;
      const f = extractFeatures(input);
      collected.push(f);
      if (collected.length >= 12) { // short recording
        processor.onaudioprocess = null;

        training[ch] = collected;  // store samples
        localStorage.voiceTraining = JSON.stringify(training);

        log("Saved training for: "+ch+" ("+collected.length+" samples)");
        resolve();
      }
    };
  });
}

// Start recognition
async function startRecognition(){
  await initAudio();
  running = true;
  log("Recognition started");

  processor.onaudioprocess = (e)=>{
    if (!running) return;

    const f = extractFeatures(e.inputBuffer);
    let best = null;
    let bestDist = Infinity;

    for (const ch in training) {
      const samples = training[ch];
      for (const s of samples){
        const d = dist(f,s);
        if (d < bestDist){
          bestDist = d;
          best = ch;
        }
      }
    }

    if (best !== null) {
      document.getElementById("out").textContent += best;
    }
  };
}

function stopRecognition(){
  running = false;
  log("Stopped recognition.");
}

function clearTraining(){
  localStorage.removeItem("voiceTraining");
  training = {};
  log("Training cleared.");
}

</script>
</body>
</html>
